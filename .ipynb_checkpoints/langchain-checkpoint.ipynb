{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde7558-17f2-4fe2-a33d-0284c9470b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl http://localhost:8080/embeddings -X POST -H \"Content-Type: application/json\" -d '{\"input\": \"Your text string goes here\", \"model\": \"text-embedding-ada-002\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8985ac6a-9934-4ab3-9663-126ceb418b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created\":1708158369,\"object\":\"chat.completion\",\"id\":\"488992f7-5299-4bf5-b173-19a3057d49a6\",\"model\":\"mixtral\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"message\":{\"role\":\"assistant\",\"content\":\"I'm just a computer program, so I don't have feelings or emotions. I'm here to help answer your questions to the best of my ability. Is there something specific you would like to know?\\n\\nIf you're asking about the status of my operation, I'm currently functioning as intended. Thank you for asking! Is there anything I can help you with?\"}}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":0,\"total_tokens\":0}}"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:8080/v1/chat/completions -H \"Content-Type: application/json\" -d '{ \"model\": \"mixtral\", \"messages\": [{\"role\": \"user\", \"content\": \"How are you?\"}], \"temperature\": 0.9 }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc275fa6-8576-4f98-860d-712bc73ff2b4",
   "metadata": {},
   "source": [
    "# Langchain Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd89213-7f6d-450d-80e9-c8144761209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ecb6b3-5ac1-4940-a7ab-30028a635f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0d0f45-603c-4282-9b2f-42e31f1c2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:8080/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff981a43-0d58-46db-af0a-9ff1ada125ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"mixtral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3eac38-29c6-4b85-8a47-95a45d076411",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4aaa2e-806f-4fc0-9bdd-9c1632f60ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7469c6-496e-4241-b200-5bab76043fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9daf5c18-7a4a-452f-b464-9e34f1a8d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't ice creams ever argue?\n",
      "\n",
      "Because they always cool down before things heat up!\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c20a4f-5f6b-469c-9b41-1f8c12716fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't ice creams ever argue?\\n\\nBecause they always cool down before things heat up!\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | model).invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8809200c-a30f-4959-9e53-073a10b7f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt).invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b884dd-c903-411b-aa64-7c7daa7efb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf79d5ed-9f4a-4400-b93b-b41b6abe9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af937f4d-5c4f-4eaf-9184-b0951c640b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:8080/v1\", api_key=\"NONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efd8588-e543-4341-b175-0d2e582ad4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, units=\"metric\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    url = f\"https://api.tomorrow.io/v4/weather/realtime?location={location.lower()}&units={units}&apikey=hZdpIwxHljGjU8UCsACtOQla3Ct4mZs2\"\n",
    "\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    \n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    weather_info = response['data']\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e225cba0-0b3f-4d89-a623-13280ce03817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"time\": \"2024-02-22T07:49:00Z\", \"values\": {\"cloudBase\": 0.23, \"cloudCeiling\": 0.23, \"cloudCover\": 99, \"dewPoint\": 20.38, \"freezingRainIntensity\": 0, \"humidity\": 90, \"precipitationProbability\": 100, \"pressureSurfaceLevel\": 1005.54, \"rainIntensity\": 1.21, \"sleetIntensity\": 0, \"snowIntensity\": 0, \"temperature\": 24.88, \"temperatureApparent\": 24.88, \"uvHealthConcern\": 1, \"uvIndex\": 2, \"visibility\": 7.51, \"weatherCode\": 4200, \"windDirection\": 219.69, \"windGust\": 2.13, \"windSpeed\": 0.63}}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(\"silchar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b3f59f6-695d-4d70-9514-3e8096c52346",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. 'san francisco' or 'new york' or 'bengaluru' or 'toronro'\",\n",
    "                    },\n",
    "                    \"units\": {\"type\": \"string\", \"enum\": [\"metric\", \"imperial\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe1aa5e-62b0-41b6-94cb-3c6362c942dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Silchar?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d491e7-7c3a-40c8-8086-64b0a91e5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"mixtral\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1537eb48-f88f-497a-81fd-1a72a4115263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{\"location\":\"Silchar\",\"units\":\"metric\"}', name='get_current_weather', function='get_current_weather')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "691726a7-051b-4787-9b89-3c3bd2d0dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_message.function_call:\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    function_name = response_message.function_call.name\n",
    "    fuction_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = fuction_to_call(\n",
    "        **function_args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebe9093a-4905-48e3-80fd-56401f197994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"time\": \"2024-02-22T08:09:00Z\", \"values\": {\"cloudBase\": 0.21, \"cloudCeiling\": 0.21, \"cloudCover\": 100, \"dewPoint\": 20.19, \"freezingRainIntensity\": 0, \"humidity\": 91, \"precipitationProbability\": 100, \"pressureSurfaceLevel\": 1005.51, \"rainIntensity\": 2.45, \"sleetIntensity\": 0, \"snowIntensity\": 0, \"temperature\": 24.81, \"temperatureApparent\": 24.81, \"uvHealthConcern\": 1, \"uvIndex\": 2, \"visibility\": 4.17, \"weatherCode\": 4200, \"windDirection\": 302.31, \"windGust\": 2.31, \"windSpeed\": 1.63}}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac0585f-45e5-4f3b-a41c-bdc6e6854472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in Silchar?\"},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"Silchar\",\"units\":\"metric\"}', name='get_current_weather', function='get_current_weather'), tool_calls=None),\n",
       " {'role': 'function',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '{\"time\": \"2024-02-22T08:09:00Z\", \"values\": {\"cloudBase\": 0.21, \"cloudCeiling\": 0.21, \"cloudCover\": 100, \"dewPoint\": 20.19, \"freezingRainIntensity\": 0, \"humidity\": 91, \"precipitationProbability\": 100, \"pressureSurfaceLevel\": 1005.51, \"rainIntensity\": 2.45, \"sleetIntensity\": 0, \"snowIntensity\": 0, \"temperature\": 24.81, \"temperatureApparent\": 24.81, \"uvHealthConcern\": 1, \"uvIndex\": 2, \"visibility\": 4.17, \"weatherCode\": 4200, \"windDirection\": 302.31, \"windGust\": 2.31, \"windSpeed\": 1.63}}'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if response_message.function_call:\n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )  # extend conversation with function response\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d45033fb-7728-4aa9-ab16-74b0f8b07f94",
   "metadata": {},
   "outputs": [],
   "source": [
    " second_response = client.chat.completions.create(\n",
    "        model=\"mixtral\",\n",
    "        messages=messages,\n",
    "    )  # get a new response from GPT where it can see the function response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "428702cd-7e41-46da-a322-c94def2319f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, the current weather in Silchar at the specified time is as follows:\n",
      "\n",
      "* The temperature is 24.81째C, with an apparent temperature of 24.81째C.\n",
      "* The relative humidity is 91%.\n",
      "* The dew point is 20.19째C.\n",
      "* The visibility is currently 4.17 km.\n",
      "* The wind is coming from a direction of 302.31째 with a speed of 1.63 m/s and a gust of 2.31 m/s.\n",
      "* The weather code is 4200, which indicates moderate rain.\n",
      "* The cloud cover is 100%, with a cloud base of 0.21 and a cloud ceiling of 0.21.\n",
      "* The precipitation probability is 100%, with a rain intensity of 2.45 mm/h.\n",
      "* The freezing rain intensity, sleet intensity, and snow intensity are all 0 mm/h.\n",
      "* The atmospheric pressure at the surface level is 1005.51 hPa.\n",
      "* The UV health concern is 1, and the UV index is 2.\n",
      "\n",
      "I hope this information helps! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c271d77-4f39-421f-811b-fd6b9b0a15ec",
   "metadata": {},
   "source": [
    "# Langchain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01d2f6-9ce1-4a15-8ce4-f6b5030705af",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe8c96-a32a-4b09-8d30-c43fee045c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40799bf-8df7-4547-8b42-02f4317e589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent, tool\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "614b0a65-9c50-4d28-b47b-e3e35a77e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:8080/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136f97a-b23c-45bd-842b-9120fb6052cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3d096e-42cc-4084-a546-3e36895e0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a6a783-61ed-432b-bafa-a7e0c6d96550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de9e4ef-da60-482f-a481-e01b40f44f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of the word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a66d18-539a-4569-bf99-5744cf53b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_word_length(word: str) -> int - Returns the length of the word.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa7376bd-7679-4df0-b102-9e1c20829ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e2b0962-2d75-47d0-bd41-6fed34d0e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"mixtral\", streaming=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7bed4be-1875-4b6e-8f2a-28fc822d47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c747a15-40cf-4c54-8fda-b26e058d5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3a26960-d6ca-4739-94c3-d449cd1edaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the length of the word \"theschoolofai\". I can use the `get_word_length` function to do this.\n",
      "\n",
      "Action: get_word_length\n",
      "Action Input: theschoolofai\u001b[0m\u001b[36;1m\u001b[1;3m13\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer. The word \"theschoolofai\" has 13 letters in it.\n",
      "Final Answer: The word \"theschoolofai\" has 13 letters in it.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = await agent_executor.ainvoke({\"input\": \"how many letters in the word theschoolofai?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeae1f6-33d5-4200-b234-f05755d8adde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
